# Bose RAG System with Phi-2

Complete RAG (Retrieval-Augmented Generation) system for Bose technical documentation using the Phi-2 LLM.

## âœ¨ Features

- ğŸš€ **Fast Local Processing** - Phi-2 model runs locally (1.6GB)
- ğŸ”’ **100% Private** - All processing happens on your machine
- ğŸ“„ **Multi-Format Support** - Text, tables, and images from PDFs
- ğŸ¯ **Smart Retrieval** - Content-aware document retrieval
- ğŸŒ **Web Interface** - Easy-to-use Gradio interface
- âš¡ **Quick Responses** - 2-3 seconds per query

---

## ğŸš€ Quick Start

### 1. Prerequisites

```powershell
# Install Ollama
winget install Ollama.Ollama

# Pull Phi model
ollama pull phi

# Start Ollama (in a separate terminal)
ollama serve
```

### 2. Install Dependencies

```powershell
# Clone the repository
git clone <your-repo-url>
cd bose-rag-project

# Create virtual environment
python -m venv venv
.\venv\Scripts\Activate.ps1

# Install packages
pip install -r requirements.txt
```

### 3. Configure Environment

Copy `.env.example` to `.env` and adjust settings if needed:

```env
OLLAMA_MODEL=phi
OLLAMA_BASE_URL=http://localhost:11434
EMBEDDING_MODEL=all-MiniLM-L6-v2
```

### 4. Add Documents

Place your PDF files in `data/documents/`

### 5. Process Documents

```powershell
python scripts\demo.py
```

This will:
- Detect content types (text, tables, images)
- Extract and chunk documents
- Generate embeddings
- Store in vector database

### 6. Launch Application

**Option A: Simple Launch Script**
```powershell
.\launch.ps1
```

**Option B: Manual Launch**
```powershell
python scripts\launch_app.py
```

**Option C: Direct Gradio Launch**
```powershell
python src\interfaces\gradio_app.py
```

Access the web interface at: **http://localhost:7860**

---

## ğŸ“– Usage

### Web Interface

1. **Upload Documents** - Click "Upload Documents" tab
2. **Process** - Select PDF files and click "Process Documents"
3. **Ask Questions** - Go to "Ask Questions" tab and enter your query
4. **View Results** - Get answers with source citations

### CLI Demo

```powershell
python scripts\demo.py
```

Interactive Q&A session with pre-loaded documents.

### Check Database

```powershell
# View database contents
python scripts\check_db.py

# Clear database
python scripts\clear_db.py
```

---

## ğŸ“ Project Structure

```
bose-rag-project/
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.py          # Configuration
â”‚   â””â”€â”€ constants.py         # Constants
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ content_detection/
â”‚   â”‚   â””â”€â”€ detector.py      # Content type detection
â”‚   â”‚
â”‚   â”œâ”€â”€ document_processing/
â”‚   â”‚   â”œâ”€â”€ text_processor.py
â”‚   â”‚   â”œâ”€â”€ table_processor.py
â”‚   â”‚   â”œâ”€â”€ image_processor.py
â”‚   â”‚   â””â”€â”€ router.py
â”‚   â”‚
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â””â”€â”€ embedder.py
â”‚   â”‚
â”‚   â”œâ”€â”€ vector_store/
â”‚   â”‚   â””â”€â”€ chromadb_manager.py
â”‚   â”‚
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â””â”€â”€ content_aware_retriever.py
â”‚   â”‚
â”‚   â”œâ”€â”€ generation/
â”‚   â”‚   â”œâ”€â”€ llm_handler_phi.py
â”‚   â”‚   â”œâ”€â”€ prompt_builder.py
â”‚   â”‚   â””â”€â”€ response_formatter.py
â”‚   â”‚
â”‚   â”œâ”€â”€ error_handling/
â”‚   â”‚   â”œâ”€â”€ handlers.py
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â”‚
â”‚   â””â”€â”€ interfaces/
â”‚       â”œâ”€â”€ rag_phi.py       # Main RAG class
â”‚       â””â”€â”€ gradio_app.py    # Web interface
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ documents/           # Place PDFs here
â”‚   â””â”€â”€ vector_db/           # Database storage
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ demo.py              # Demo script
â”‚   â”œâ”€â”€ launch_app.py        # Application launcher
â”‚   â”œâ”€â”€ check_db.py          # Database checker
â”‚   â””â”€â”€ clear_db.py          # Database cleaner
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ launch.ps1               # Quick launch script
â”œâ”€â”€ DEPLOYMENT.md            # Deployment guide
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Configuration

Edit `.env` file:

```env
# Model Configuration
OLLAMA_MODEL=phi
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TEMPERATURE=0.7

# Processing
CHUNK_SIZE=500
CHUNK_OVERLAP=50
TOP_K_RESULTS=5

# Embeddings
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Generation
MAX_TOKENS=512
RESPONSE_TIMEOUT=60

# Logging
LOG_LEVEL=INFO
```

---

## ğŸ”§ Troubleshooting

### Ollama Connection Error

```powershell
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Start Ollama
ollama serve
```

### Model Not Found

```powershell
# Pull the model
ollama pull phi

# List available models
ollama list
```

### No Search Results

```powershell
# Check database
python scripts\check_db.py

# Reprocess documents if empty
python scripts\clear_db.py
python scripts\demo.py
```

### Port Already in Use

Change port in `src/interfaces/gradio_app.py`:
```python
server_port=7861  # Change to available port
```

### Import Errors

```powershell
# Reinstall dependencies
pip install --upgrade -r requirements.txt
```

---

## ğŸ“Š Example Queries

- "What is the maximum number of analog inputs on the EX-1280C?"
- "Which software version is required for PC configuration?"
- "What are the specifications of DesignMax DM8SE?"
- "How do I install ControlSpace?"
- "What is the frequency response?"

---

## ğŸš€ Deployment

See [DEPLOYMENT.md](DEPLOYMENT.md) for detailed deployment options:

- Local deployment with Gradio
- Production deployment with FastAPI
- Docker deployment
- Cloud deployment (AWS, Azure, GCP)
- Windows Service

---

## ğŸ“ Development

### Run Tests

```powershell
pytest tests/
```

### Check Code Quality

```powershell
# Format code
black src/

# Lint
flake8 src/
```

### View Logs

```powershell
Get-Content rag_system.log -Tail 50 -Wait
```

---

## ğŸ”’ Security

- All processing happens locally
- No data sent to external APIs
- Documents stored locally
- Optional authentication for web interface
- Use HTTPS in production

---

## ğŸ“„ License

[Your License Here]

---

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

---

## ğŸ“ Support

For issues:
1. Check logs: `rag_system.log`
2. Run database check: `python scripts\check_db.py`
3. Review [DEPLOYMENT.md](DEPLOYMENT.md)
4. Open an issue on GitHub

---

## ğŸ™ Acknowledgments

- **Phi-2** by Microsoft Research
- **Ollama** for local LLM serving
- **LangChain** for RAG framework
- **ChromaDB** for vector storage
- **Gradio** for web interface

---

**Built with â¤ï¸ for Bose Technical Documentation**
